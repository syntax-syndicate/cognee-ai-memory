{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install owlready2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0f3dbe",
   "metadata": {},
   "source": [
    "# Graphrag Ontology Integration Demo\n",
    "\n",
    "This demonstration shows how graphrag works both with and without ontology integration, highlighting the differences, benefits, and practical applications of using ontological knowledge in a knowledge graph system.\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this demo, we'll:\n",
    "1. Process data without ontology integration\n",
    "2. Process the same data with ontology integration\n",
    "3. Compare search results between the two approaches\n",
    "4. Visualize the differences in knowledge graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6259f43",
   "metadata": {},
   "source": [
    "## 1. Setup and Environment\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f997ca",
   "metadata": {},
   "source": [
    "First, let's set up our environment with the necessary imports:"
   ]
  },
  {
   "cell_type": "code",
   "id": "466e6aa8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T06:13:46.197435Z",
     "start_time": "2025-02-26T06:13:46.191277Z"
    }
   },
   "source": [
    "import os\n",
    "import asyncio\n",
    "import pathlib\n",
    "from typing import List\n",
    "\n",
    "# Import Cognee utilities\n",
    "from utils import (\n",
    "setup_logging, \n",
    "visualize_graph,\n",
    "get_datasets,\n",
    "get_dataset_data,\n",
    "prune_data,\n",
    "prune_system,\n",
    "add,\n",
    "search,\n",
    "SearchType,\n",
    "get_default_user,\n",
    "KnowledgeGraph,\n",
    "add_data_points\n",
    ")\n",
    "\n",
    "# Import the ontology handling functions\n",
    "from ontology_demo import (\n",
    "owl_testing_pipeline,\n",
    "owl_ontology_merging_layer\n",
    ")\n",
    "\n",
    "import logging\n",
    "setup_logging(logging.INFO)\n",
    "from cognee.tasks.graph import extract_graph_from_data\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "09462fc7",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9050ae5f",
   "metadata": {},
   "source": [
    "We'll use the same test data for both approaches:"
   ]
  },
  {
   "cell_type": "code",
   "id": "839ec02a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T06:13:49.310556Z",
     "start_time": "2025-02-26T06:13:49.307838Z"
    }
   },
   "source": [
    "async def prepare_data():\n",
    "    # Clean previous data\n",
    "    await prune_data()\n",
    "    await prune_system(metadata=True)\n",
    "    \n",
    "    # Add test data - the path should point to your data files\n",
    "    current_dir = os.getcwd()\n",
    "    parent_dir = os.path.dirname(current_dir)\n",
    "    file_path = os.path.join(parent_dir, \"ontology_test_input\")\n",
    "    # file_path = os.path.join(\n",
    "    #     os.path.abspath(os.path.join(os.path.dirname(os.path.abspath(__file__)), os.pardir)),\n",
    "    #     \"ontology_test_input\"\n",
    "    # )\n",
    "    await add(file_path)\n",
    "    \n",
    "    print(\"Data prepared successfully\")\n"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "id": "5ed7d228",
   "metadata": {},
   "source": [
    "## 3. Standard Knowledge Graph Processing (Without Ontology)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b865bcdb",
   "metadata": {},
   "source": [
    "Let's process our data using the standard graphrag pipeline without ontology integration:"
   ]
  },
  {
   "cell_type": "code",
   "id": "075f3bb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T06:13:51.165411Z",
     "start_time": "2025-02-26T06:13:51.149132Z"
    }
   },
   "source": [
    "async def process_without_ontology():\n",
    "    # Get the dataset to process\n",
    "    user = await get_default_user()\n",
    "    datasets = await get_datasets(user.id)\n",
    "    \n",
    "    if not datasets:\n",
    "        print(\"No datasets found!\")\n",
    "        return\n",
    "    \n",
    "    # Use the standard pipeline\n",
    "    from utils import (\n",
    "        run_tasks,\n",
    "        Task,\n",
    "        classify_documents,\n",
    "        check_permissions_on_documents,\n",
    "        extract_chunks_from_documents,\n",
    "        extract_content_graph,\n",
    "        get_max_chunk_tokens\n",
    "    )\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        data_documents = await get_dataset_data(dataset_id=dataset.id)\n",
    "\n",
    "        \n",
    "        tasks = [\n",
    "            Task(classify_documents),\n",
    "            Task(check_permissions_on_documents, user=user, permissions=[\"write\"]),\n",
    "            Task(extract_chunks_from_documents, max_chunk_tokens=get_max_chunk_tokens()),\n",
    "            Task(\n",
    "                extract_graph_from_data, graph_model=KnowledgeGraph, task_config={\"batch_size\": 10}\n",
    "            ),  # Generate knowledge graphs from the document chunks.\n",
    "            Task(add_data_points, task_config={\"batch_size\": 10}),\n",
    "        ]\n",
    "        \n",
    "        \n",
    "        pipeline_run = run_tasks(tasks, dataset.id, data_documents, \"standard_pipeline\")\n",
    "        \n",
    "        async for run_status in pipeline_run:\n",
    "            print(run_status)\n",
    "    \n",
    "    # Save graph visualization\n",
    "    notebook_dir = pathlib.Path.cwd()\n",
    "    output_dir = notebook_dir / \".artifacts\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    standard_graph_path = (output_dir / \"standard_graph_visualization.html\").resolve()\n",
    "    await visualize_graph(str(standard_graph_path))\n",
    "    \n",
    "    print(f\"Standard graph saved to: {standard_graph_path}\")\n",
    "    return standard_graph_path"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "fe93b9c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T06:13:51.837903Z",
     "start_time": "2025-02-26T06:13:51.830543Z"
    }
   },
   "source": [
    "import pathlib\n",
    "import os\n",
    "from utils  import visualize_graph\n",
    "\n",
    "# Use the current working directory instead of __file__:\n",
    "notebook_dir = pathlib.Path.cwd()\n",
    "\n",
    "graph_file_path = (notebook_dir / \".artifacts\" / \"graph_visualization.html\").resolve()\n",
    "\n",
    "# Make sure to convert to string if visualize_graph expects a string\n",
    "b = await visualize_graph(str(graph_file_path))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-25 22:13:51,832 - WARNING - File /Users/vasilije/cognee/cognee/.cognee_system/databases/cognee_graph.pkl not found. Initializing an empty graph.\n",
      "2025-02-25 22:13:51,836 - INFO - Graph visualization saved as /Users/vasilije/cognee/cognee/ontology_testing_SANDBOX/Ontology_demo/.artifacts/graph_visualization.html\n",
      "2025-02-25 22:13:51,836 - INFO - The HTML file has been stored at path: /Users/vasilije/cognee/cognee/ontology_testing_SANDBOX/Ontology_demo/.artifacts/graph_visualization.html\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "id": "ef009ee7",
   "metadata": {},
   "source": [
    "## 4. Ontology-Enhanced Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0234f4f4",
   "metadata": {},
   "source": [
    "\n",
    "Now, let's process the same data with ontology integration:"
   ]
  },
  {
   "cell_type": "code",
   "id": "af291c5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T06:13:56.968978Z",
     "start_time": "2025-02-26T06:13:56.966072Z"
    }
   },
   "source": [
    "\n",
    "async def process_with_ontology():\n",
    "    # This uses the owl_testing_pipeline from ontology_demo.py\n",
    "    await owl_testing_pipeline()\n",
    "    \n",
    "    # Save graph visualization\n",
    "    notebook_dir = pathlib.Path.cwd()\n",
    "    output_dir = notebook_dir / \".artifacts\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    ontology_graph_path = (output_dir / \"ontology_graph_visualization.html\").resolve()\n",
    "    await visualize_graph(str(ontology_graph_path))\n",
    "    \n",
    "    print(f\"Ontology-enhanced graph saved to: {ontology_graph_path}\")\n",
    "    return ontology_graph_path"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "id": "44ae5800",
   "metadata": {},
   "source": [
    "## 5. Comparing Search Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3878d623",
   "metadata": {},
   "source": [
    "\n",
    "Let's execute some queries to compare the results:"
   ]
  },
  {
   "cell_type": "code",
   "id": "3bbb2603",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T06:13:59.467229Z",
     "start_time": "2025-02-26T06:13:59.462646Z"
    }
   },
   "source": [
    "\n",
    "async def compare_search_results():\n",
    "    # Sample queries for testing\n",
    "    queries = [\n",
    "        \"What are the exact cars produced by Audi and what are their types?\",\n",
    "        \"What features do luxury cars have?\",\n",
    "        \"Tell me about vehicle manufacturers and their relationships\"\n",
    "    ]\n",
    "    \n",
    "    print(\"==== STANDARD KNOWLEDGE GRAPH SEARCH RESULTS ====\")\n",
    "    # First, search using the standard graph\n",
    "    await prune_data(keep_dataset=True)  # Keep dataset but remove processing results\n",
    "    await process_without_ontology()\n",
    "    \n",
    "    for query in queries:\n",
    "        print(f\"\\nQuery: {query}\")\n",
    "        results = await search(query_type=SearchType.GRAPH_COMPLETION, query_text=query)\n",
    "        print(\"Results:\")\n",
    "        for i, result in enumerate(results[:3]):\n",
    "            print(f\"{i+1}. {result}\")\n",
    "    \n",
    "    print(\"\\n==== ONTOLOGY-ENHANCED KNOWLEDGE GRAPH SEARCH RESULTS ====\")\n",
    "    # Now, search using the ontology-enhanced graph\n",
    "    await prune_data(keep_dataset=True)  # Keep dataset but remove processing results\n",
    "    await process_with_ontology()\n",
    "    \n",
    "    for query in queries:\n",
    "        print(f\"\\nQuery: {query}\")\n",
    "        results = await search(query_type=SearchType.GRAPH_COMPLETION, query_text=query)\n",
    "        print(\"Results:\")\n",
    "        for i, result in enumerate(results[:3]):\n",
    "            print(f\"{i+1}. {result}\")\n"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "id": "e24404e0",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Key Differences and Benefits\n",
    "\n",
    "### Without Ontology:\n",
    "- **Knowledge is limited to extracted information**: Only relationships and entities explicitly mentioned in the text are captured\n",
    "- **No hierarchical understanding**: Lacks class/subclass relationships unless explicitly stated\n",
    "- **Missing implicit connections**: Cannot infer relationships that weren't explicitly stated\n",
    "- **Domain knowledge is limited**: No external domain knowledge beyond the processed content\n",
    "\n",
    "### With Ontology:\n",
    "- **Enhanced semantic understanding**: Integration with domain ontologies provides richer semantic context\n",
    "- **Hierarchical relationships**: Class/subclass relationships from the ontology enrich the graph\n",
    "- **Inference capabilities**: Can infer relationships based on ontological axioms\n",
    "- **Domain knowledge enrichment**: External knowledge from the ontology supplements extracted information\n",
    "- **Standardized terminology**: Entities are mapped to standardized ontology concepts\n",
    "- **Better query answering**: More comprehensive answers due to extended knowledge\n",
    "\n",
    "## 7. Visualizations and Metrics\n",
    "\n",
    "Here are some key metrics to observe in the visualizations:\n",
    "\n",
    "1. **Node count**: The ontology-enhanced graph typically has more nodes\n",
    "2. **Edge density**: More connections between nodes in the ontology version\n",
    "3. **Clustering coefficient**: Often higher in the ontology version due to richer relationships\n",
    "4. **Average path length**: May be shorter in the ontology version due to additional connections\n",
    "5. **Connected components**: The ontology version usually has fewer isolated subgraphs\n",
    "\n",
    "## 8. Running the Demo\n",
    "\n",
    "Execute the following to run the complete demo:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "69292dd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T06:14:50.936865Z",
     "start_time": "2025-02-26T06:14:07.449868Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "print(\"Starting Ontology Comparison Demo\")\n",
    "await prepare_data()\n",
    "\n",
    "print(\"\\nProcessing without ontology...\")\n",
    "standard_graph = await process_without_ontology()\n",
    "\n",
    "print(\"\\nProcessing with ontology...\")\n",
    "ontology_graph = await process_with_ontology()\n",
    "\n",
    "print(\"\\nComparing search results...\")\n",
    "await compare_search_results()\n",
    "\n",
    "print(\"\\nDemo completed!\")\n",
    "print(f\"Standard graph visualization: {standard_graph}\")\n",
    "print(f\"Ontology graph visualization: {ontology_graph}\")\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Ontology Comparison Demo\n",
      "2025-02-25 22:14:07,451 - INFO - Graph deleted successfully.\n",
      "2025-02-25 22:14:07,456 - INFO - Database deleted successfully.\n",
      "User d4017493-773a-447e-b66f-9b186b6e4301 has registered.\n",
      "<cognee.modules.pipelines.models.PipelineRun.PipelineRun object at 0x121a69390>\n",
      "2025-02-25 22:14:07,532 - INFO - Pipeline run started: `4b84e400-23fc-5976-bbb4-f8ee303eed81`\n",
      "2025-02-25 22:14:07,533 - INFO - Coroutine task started: `resolve_data_directories`\n",
      "2025-02-25 22:14:07,533 - INFO - Coroutine task started: `ingest_data`\n",
      "2025-02-25 22:14:07,761 - INFO - Coroutine task completed: `ingest_data`\n",
      "2025-02-25 22:14:07,761 - INFO - Coroutine task completed: `resolve_data_directories`\n",
      "2025-02-25 22:14:07,761 - INFO - Pipeline run completed: `4b84e400-23fc-5976-bbb4-f8ee303eed81`\n",
      "<cognee.modules.pipelines.models.PipelineRun.PipelineRun object at 0x121780650>\n",
      "Data prepared successfully\n",
      "\n",
      "Processing without ontology...\n",
      "<cognee.modules.pipelines.models.PipelineRun.PipelineRun object at 0x121fb3550>\n",
      "2025-02-25 22:14:07,777 - INFO - Pipeline run started: `ea9bd1d8-7bd9-5908-a88b-1192a13ed265`\n",
      "2025-02-25 22:14:07,777 - INFO - Coroutine task started: `classify_documents`\n",
      "2025-02-25 22:14:07,778 - INFO - Coroutine task started: `check_permissions_on_documents`\n",
      "2025-02-25 22:14:07,780 - INFO - Async generator task started: `extract_chunks_from_documents`\n",
      "2025-02-25 22:14:19,660 - INFO - Coroutine task started: `extract_graph_from_data`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m22:14:19 - LiteLLM:INFO\u001B[0m: utils.py:2784 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-25 22:14:19,678 - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m22:14:19 - LiteLLM:INFO\u001B[0m: utils.py:2784 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-25 22:14:19,681 - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-02-25 22:14:23,469 - WARNING - File /Users/vasilije/cognee/cognee/.cognee_system/databases/cognee_graph.pkl not found. Initializing an empty graph.\n",
      "2025-02-25 22:14:24,787 - INFO - Coroutine task started: `add_data_points`\n",
      "2025-02-25 22:14:26,201 - INFO - Coroutine task completed: `add_data_points`\n",
      "2025-02-25 22:14:26,201 - INFO - Coroutine task completed: `extract_graph_from_data`\n",
      "2025-02-25 22:14:26,202 - INFO - Async generator task completed: `extract_chunks_from_documents`\n",
      "2025-02-25 22:14:26,202 - INFO - Coroutine task completed: `check_permissions_on_documents`\n",
      "2025-02-25 22:14:26,202 - INFO - Coroutine task completed: `classify_documents`\n",
      "2025-02-25 22:14:26,202 - INFO - Pipeline run completed: `ea9bd1d8-7bd9-5908-a88b-1192a13ed265`\n",
      "<cognee.modules.pipelines.models.PipelineRun.PipelineRun object at 0x121f21c90>\n",
      "2025-02-25 22:14:26,211 - INFO - Graph visualization saved as /Users/vasilije/cognee/cognee/ontology_testing_SANDBOX/Ontology_demo/.artifacts/standard_graph_visualization.html\n",
      "2025-02-25 22:14:26,211 - INFO - The HTML file has been stored at path: /Users/vasilije/cognee/cognee/ontology_testing_SANDBOX/Ontology_demo/.artifacts/standard_graph_visualization.html\n",
      "Standard graph saved to: /Users/vasilije/cognee/cognee/ontology_testing_SANDBOX/Ontology_demo/.artifacts/standard_graph_visualization.html\n",
      "\n",
      "Processing with ontology...\n",
      "Ontology loaded successfully.\n",
      "<cognee.modules.pipelines.models.PipelineRun.PipelineRun object at 0x1222d4e10>\n",
      "2025-02-25 22:14:26,230 - INFO - Pipeline run started: `af81ab41-8243-522f-a10a-b7b5febcc577`\n",
      "2025-02-25 22:14:26,230 - INFO - Coroutine task started: `classify_documents`\n",
      "2025-02-25 22:14:26,230 - INFO - Coroutine task started: `check_permissions_on_documents`\n",
      "2025-02-25 22:14:26,233 - INFO - Async generator task started: `extract_chunks_from_documents`\n",
      "2025-02-25 22:14:37,859 - INFO - Coroutine task started: `owl_ontology_merging_layer`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m22:14:37 - LiteLLM:INFO\u001B[0m: utils.py:2784 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-25 22:14:37,864 - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m22:14:37 - LiteLLM:INFO\u001B[0m: utils.py:2784 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-25 22:14:37,866 - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-02-25 22:14:49,526 - INFO - Coroutine task completed: `owl_ontology_merging_layer`\n",
      "2025-02-25 22:14:49,526 - INFO - Async generator task completed: `extract_chunks_from_documents`\n",
      "2025-02-25 22:14:49,526 - INFO - Coroutine task completed: `check_permissions_on_documents`\n",
      "2025-02-25 22:14:49,526 - INFO - Coroutine task completed: `classify_documents`\n",
      "2025-02-25 22:14:49,527 - INFO - Pipeline run completed: `af81ab41-8243-522f-a10a-b7b5febcc577`\n",
      "<cognee.modules.pipelines.models.PipelineRun.PipelineRun object at 0x1228a0d50>\n",
      "The query is What are the exact cars produced by Audi and what are their types?:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m22:14:50 - LiteLLM:INFO\u001B[0m: utils.py:2784 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-25 22:14:50,329 - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "{\"Audi_cars\": [\"Audi_etron\", \"Audi_r8\", \"Audi_a8\"]}\n",
      "2025-02-25 22:14:50,914 - INFO - Graph visualization saved as /Users/vasilije/cognee/cognee/ontology_testing_SANDBOX/Ontology_demo/.artifacts/ontology_graph_visualization.html\n",
      "2025-02-25 22:14:50,915 - INFO - The HTML file has been stored at path: /Users/vasilije/cognee/cognee/ontology_testing_SANDBOX/Ontology_demo/.artifacts/ontology_graph_visualization.html\n",
      "Ontology-enhanced graph saved to: /Users/vasilije/cognee/cognee/ontology_testing_SANDBOX/Ontology_demo/.artifacts/ontology_graph_visualization.html\n",
      "\n",
      "Comparing search results...\n",
      "==== STANDARD KNOWLEDGE GRAPH SEARCH RESULTS ====\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "prune_data() got an unexpected keyword argument 'keep_dataset'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[22], line 11\u001B[0m\n\u001B[1;32m      8\u001B[0m ontology_graph \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m process_with_ontology()\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mComparing search results...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 11\u001B[0m \u001B[38;5;28;01mawait\u001B[39;00m compare_search_results()\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mDemo completed!\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mStandard graph visualization: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstandard_graph\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[0;32mIn[21], line 11\u001B[0m, in \u001B[0;36mcompare_search_results\u001B[0;34m()\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m==== STANDARD KNOWLEDGE GRAPH SEARCH RESULTS ====\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# First, search using the standard graph\u001B[39;00m\n\u001B[0;32m---> 11\u001B[0m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[43mprune_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkeep_dataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Keep dataset but remove processing results\u001B[39;00m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mawait\u001B[39;00m process_without_ontology()\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m query \u001B[38;5;129;01min\u001B[39;00m queries:\n",
      "\u001B[0;31mTypeError\u001B[0m: prune_data() got an unexpected keyword argument 'keep_dataset'"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cad9819200293b7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T06:14:50.939123Z",
     "start_time": "2025-02-26T05:30:28.184445Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://raw.githubusercontent.com/BerriAI/litellm/main/model_prices_and_context_window.json \"HTTP/1.1 200 OK\"/Users/vasilije/cognee/.venv/lib/python3.11/site-packages/pydantic/_internal/_config.py:345: UserWarning: Valid config keys have changed in V2:\n",
      "* 'fields' has been removed\n",
      "  warnings.warn(message, UserWarning)\n",
      "/Users/vasilije/cognee/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO:cognee.modules.visualization.cognee_network_visualization:Graph visualization saved as /Users/vasilije/cognee/cognee/ontology_testing_SANDBOX/Ontology_demo/.artifacts/graph_visualization.htmlINFO:root:The HTML file has been stored at path: /Users/vasilije/cognee/cognee/ontology_testing_SANDBOX/Ontology_demo/.artifacts/graph_visualization.html"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90ff3c07ac4b13d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T05:09:05.027576Z",
     "start_time": "2025-02-26T05:09:05.024134Z"
    }
   },
   "outputs": [],
   "source": ""
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc439d80dfdacae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T05:09:09.310652Z",
     "start_time": "2025-02-26T05:09:09.308683Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/vasilije/cognee/cognee/ontology_testing_SANDBOX/Ontology_demo\n"
     ]
    }
   ],
   "source": ""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad409b4264dcc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cognee-3fVNbOG1-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
