{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[2m2025-04-07T17:45:40.482993\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDeleted old log file: /Users/handekafkas/Documents/local-code/new-cognee/cognee/logs/2025-04-07_15-18-34.log\u001b[0m [\u001b[0m\u001b[1m\u001b[34mcognee.shared.logging_utils\u001b[0m]\u001b[0m\n",
      "\n",
      "\u001b[1mHTTP Request: GET https://raw.githubusercontent.com/BerriAI/litellm/main/model_prices_and_context_window.json \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\n",
      "\u001b[2m2025-04-07T17:45:43.445890\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mOntology file 'None' not found. Using fallback ontology at http://example.org/empty_ontology\u001b[0m [\u001b[0m\u001b[1m\u001b[34mOntologyAdapter\u001b[0m]\u001b[0m\n",
      "\u001b[2m2025-04-07T17:45:43.446560\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mLookup built: 0 classes, 0 individuals\u001b[0m [\u001b[0m\u001b[1m\u001b[34mOntologyAdapter\u001b[0m]\u001b[0m\n",
      "\u001b[2m2025-04-07T17:45:43.455349\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mOntology file 'None' not found. Using fallback ontology at http://example.org/empty_ontology\u001b[0m [\u001b[0m\u001b[1m\u001b[34mOntologyAdapter\u001b[0m]\u001b[0m\n",
      "\u001b[2m2025-04-07T17:45:43.455759\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mLookup built: 0 classes, 0 individuals\u001b[0m [\u001b[0m\u001b[1m\u001b[34mOntologyAdapter\u001b[0m]\u001b[0m"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import nest_asyncio\n",
    "\n",
    "import cognee\n",
    "from cognee.api.v1.search import SearchType\n",
    "from cognee.api.v1.visualize.visualize import visualize_graph\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[2m2025-04-07T18:17:54.906690\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDatabase deleted successfully.\u001b[0m [\u001b[0m\u001b[1m\u001b[34mcognee.shared.logging_utils\u001b[0m]\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Clears all data and system state\n",
    "\n",
    "await cognee.prune.prune_data()     \n",
    "await cognee.prune.prune_system(metadata=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_1 = \"\"\"\n",
    "1. Audi\n",
    "Audi is known for its modern designs and advanced technology. Founded in the early 1900s, the brand has earned a reputation for precision engineering and innovation. With features like the Quattro all-wheel-drive system, Audi offers a range of vehicles from stylish sedans to high-performance sports cars. Audi eTron (Electric Car), Audi R8 (Sports Car), Audi A8 (Luxury Car)\n",
    "\n",
    "2. BMW\n",
    "BMW, short for Bayerische Motoren Werke, is celebrated for its focus on performance and driving pleasure. The company’s vehicles are designed to provide a dynamic and engaging driving experience, and their slogan, \"The Ultimate Driving Machine,\" reflects that commitment. BMW produces a variety of cars that combine luxury with sporty performance. BMW 7Series (Luxury Car), BMW M4 (Sports Car), BMW iX (Electric Car)\n",
    "\n",
    "3. Mercedes-Benz\n",
    "Mercedes-Benz is synonymous with luxury and quality. With a history dating back to the early 20th century, the brand is known for its elegant designs, innovative safety features, and high-quality engineering. Mercedes-Benz manufactures not only luxury sedans but also SUVs, sports cars, and commercial vehicles, catering to a wide range of needs. Mercedes S-Class (Luxury Car), Mercedes EQS (Electric Car), Mercedes AMG GT (Sports Car)\n",
    "\n",
    "4. Porsche\n",
    "Porsche is a name that stands for high-performance sports cars. Founded in 1931, the brand has become famous for models like the iconic Porsche 911. Porsche cars are celebrated for their speed, precision, and distinctive design, appealing to car enthusiasts who value both performance and style. Porsche Cayenne (SUV), Porsche Taycan (Electric Car), Porsche 911 (Sports Car)\n",
    "\n",
    "5. Volkswagen\n",
    "Volkswagen, which means “people’s car” in German, was established with the idea of making affordable and reliable vehicles accessible to everyone. Over the years, Volkswagen has produced several iconic models, such as the Beetle and the Golf. Today, it remains one of the largest car manufacturers in the world, offering a wide range of vehicles that balance practicality with quality. Volkswagen Golf (Sedan), VW ID4 (Electric Car), VW Touareg (SUV)\n",
    "\n",
    "Each of these car manufacturer contributes to Germany's reputation as a leader in the global automotive industry, showcasing a blend of innovation, performance, and design excellence.\n",
    "\"\"\"\n",
    "\n",
    "text_2 = \"\"\"\n",
    "I am a car enthusiast.\n",
    "When choosing a vehicle, I prioritize electric cars for their sustainability and advanced technology (e.g., long-range capability, sophisticated infotainment, and autonomous features).\n",
    "However, I also enjoy high-performance sports cars that offer precise handling, aerodynamic design, and an engaging driving experience. \n",
    "For luxury sedans, I look for comfortable seating and cutting-edge safety features. \n",
    "Ultimately, I like to explore the full range of models offered by brands like Audi, BMW, Mercedes-Benz, Porsche, and Volkswagen to find the perfect balance of innovation, style, and practicality.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[2m2025-04-07T18:18:00.099321\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mPipeline run started: `4b84e400-23fc-5976-bbb4-f8ee303eed81`\u001b[0m [\u001b[0m\u001b[1m\u001b[34mrun_tasks(tasks: [Task], data)\u001b[0m]\u001b[0m/Users/handekafkas/Documents/local-code/new-cognee/cognee/.venv/lib/python3.11/site-packages/dlt/destinations/impl/sqlalchemy/merge_job.py:194: SAWarning: Table 'file_metadata' already exists within the given MetaData - not copying.\n",
      "  staging_table_obj = table_obj.to_metadata(\n",
      "/Users/handekafkas/Documents/local-code/new-cognee/cognee/.venv/lib/python3.11/site-packages/dlt/destinations/impl/sqlalchemy/merge_job.py:229: SAWarning: implicitly coercing SELECT object to scalar subquery; please use the .scalar_subquery() method to produce a scalar subquery.\n",
      "  order_by=order_dir_func(order_by_col),\n",
      "\n",
      "\u001b[2m2025-04-07T18:18:00.225004\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mPipeline run completed: `4b84e400-23fc-5976-bbb4-f8ee303eed81`\u001b[0m [\u001b[0m\u001b[1m\u001b[34mrun_tasks(tasks: [Task], data)\u001b[0m]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 490a3774-3588-432d-a050-369b4653e47f has registered.\n",
      "Pipeline run status: add_pipeline - PipelineRunStatus.DATASET_PROCESSING_STARTED\n",
      "Pipeline run status: add_pipeline - PipelineRunStatus.DATASET_PROCESSING_COMPLETED\n"
     ]
    }
   ],
   "source": [
    "text_list = [text_1, text_2]\n",
    "\n",
    "await cognee.add(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ontology_path = os.path.join(os.getcwd(), \"..\", \"examples\", \"python\", \"ontology_input_example\", \"basic_ontology.owl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[2m2025-04-07T18:18:07.531511\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mOntology loaded successfully from file: /Users/handekafkas/Documents/local-code/new-cognee/cognee/notebooks/../examples/python/ontology_input_example/basic_ontology.owl\u001b[0m [\u001b[0m\u001b[1m\u001b[34mOntologyAdapter\u001b[0m]\u001b[0m\n",
      "\u001b[2m2025-04-07T18:18:07.532750\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mLookup built: 13 classes, 45 individuals\u001b[0m [\u001b[0m\u001b[1m\u001b[34mOntologyAdapter\u001b[0m]\u001b[0m\n",
      "\u001b[2m2025-04-07T18:18:07.533231\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel not found in LiteLLM's model_cost.\u001b[0m [\u001b[0m\u001b[1m\u001b[34mcognee.shared.logging_utils\u001b[0m]\u001b[0m\n",
      "\u001b[2m2025-04-07T18:18:07.540278\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mPipeline run started: `af81ab41-8243-522f-a10a-b7b5febcc577`\u001b[0m [\u001b[0m\u001b[1m\u001b[34mrun_tasks(tasks: [Task], data)\u001b[0m]\u001b[0m\n",
      "\u001b[2m2025-04-07T18:18:07.579996\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel not found in LiteLLM's model_cost.\u001b[0m [\u001b[0m\u001b[1m\u001b[34mcognee.shared.logging_utils\u001b[0m]\u001b[0m\n",
      "\u001b[2m2025-04-07T18:18:07.597058\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel not found in LiteLLM's model_cost.\u001b[0m [\u001b[0m\u001b[1m\u001b[34mcognee.shared.logging_utils\u001b[0m]\u001b[0m\u001b[92m18:18:07 - LiteLLM:INFO\u001b[0m: utils.py:3035 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[1m\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\u001b[0m\u001b[92m18:18:07 - LiteLLM:INFO\u001b[0m: utils.py:3035 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[1m\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\u001b[0m\u001b[92m18:18:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[1mselected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\u001b[0m\u001b[92m18:18:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[1mselected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\u001b[0m\u001b[92m18:18:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[1mselected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\u001b[0m\u001b[92m18:18:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[1mselected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\u001b[0m\n",
      "\u001b[1mReceived notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 4, column: 19, offset: 84} for query: '\\n            UNWIND $edges AS edge\\n            MATCH (a)-[r]->(b)\\n            WHERE id(a) = edge.from_node AND id(b) = edge.to_node AND type(r) = edge.relationship_name\\n            RETURN edge.from_node AS from_node, edge.to_node AS to_node, edge.relationship_name AS relationship_name, count(r) > 0 AS edge_exists\\n        '\u001b[0m\n",
      "\u001b[1mReceived notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 4, column: 46, offset: 111} for query: '\\n            UNWIND $edges AS edge\\n            MATCH (a)-[r]->(b)\\n            WHERE id(a) = edge.from_node AND id(b) = edge.to_node AND type(r) = edge.relationship_name\\n            RETURN edge.from_node AS from_node, edge.to_node AS to_node, edge.relationship_name AS relationship_name, count(r) > 0 AS edge_exists\\n        '\u001b[0m\n",
      "\u001b[2m2025-04-07T18:18:22.327475\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mNo close match found for 'person' in category 'classes'\u001b[0m [\u001b[0m\u001b[1m\u001b[34mOntologyAdapter\u001b[0m]\u001b[0m\n",
      "\u001b[2m2025-04-07T18:18:22.328097\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mNo close match found for 'car enthusiast' in category 'individuals'\u001b[0m [\u001b[0m\u001b[1m\u001b[34mOntologyAdapter\u001b[0m]\u001b[0m\n",
      "\u001b[2m2025-04-07T18:18:22.328725\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mNo close match found for 'vehicle' in category 'classes'\u001b[0m [\u001b[0m\u001b[1m\u001b[34mOntologyAdapter\u001b[0m]\u001b[0m\n",
      "\u001b[2m2025-04-07T18:18:22.329361\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mNo close match found for 'electric cars' in category 'individuals'\u001b[0m [\u001b[0m\u001b[1m\u001b[34mOntologyAdapter\u001b[0m]\u001b[0m\n",
      "\u001b[2m2025-04-07T18:18:22.330157\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mNo close match found for 'high-performance sports cars' in category 'individuals'\u001b[0m [\u001b[0m\u001b[1m\u001b[34mOntologyAdapter\u001b[0m]\u001b[0m\n",
      "\u001b[2m2025-04-07T18:18:22.331037\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mNo close match found for 'luxury sedans' in category 'individuals'\u001b[0m [\u001b[0m\u001b[1m\u001b[34mOntologyAdapter\u001b[0m]\u001b[0m\n",
      "\u001b[2m2025-04-07T18:18:22.331936\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mNo close match found for 'brand' in category 'classes'\u001b[0m [\u001b[0m\u001b[1m\u001b[34mOntologyAdapter\u001b[0m]\u001b[0m\n",
      "\u001b[2m2025-04-07T18:18:22.332789\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mAudi match was found for found for 'audi' node\u001b[0m [\u001b[0m\u001b[1m\u001b[34mOntologyAdapter\u001b[0m]\u001b[0m\n",
      "\u001b[2m2025-04-07T18:18:22.335057\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mBMW match was found for found for 'bmw' node\u001b[0m [\u001b[0m\u001b[1m\u001b[34mOntologyAdapter\u001b[0m]\u001b[0m\n",
      "\u001b[2m2025-04-07T18:18:22.336295\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mMercedesBenz match was found for found for 'mercedes-benz' node\u001b[0m [\u001b[0m\u001b[1m\u001b[34mOntologyAdapter\u001b[0m]\u001b[0m\n",
      "\u001b[2m2025-04-07T18:18:22.337196\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mPorsche match was found for found for 'porsche' node\u001b[0m [\u001b[0m\u001b[1m\u001b[34mOntologyAdapter\u001b[0m]\u001b[0m\n",
      "\u001b[2m2025-04-07T18:18:22.338295\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mVolkswagen match was found for found for 'volkswagen' node\u001b[0m [\u001b[0m\u001b[1m\u001b[34mOntologyAdapter\u001b[0m]\u001b[0m\n",
      "\u001b[2m2025-04-07T18:18:22.339281\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCarManufacturer match was found for found for 'car manufacturer' node\u001b[0m [\u001b[0m\u001b[1m\u001b[34mOntologyAdapter\u001b[0m]\u001b[0m\n",
      "\u001b[2m2025-04-07T18:18:22.339899\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mMercedesBenz match was found for found for 'mercedes-benz' node\u001b[0m [\u001b[0m\u001b[1m\u001b[34mOntologyAdapter\u001b[0m]\u001b[0m\n",
      "\u001b[2m2025-04-07T18:18:22.350866\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel not found in LiteLLM's model_cost.\u001b[0m [\u001b[0m\u001b[1m\u001b[34mcognee.shared.logging_utils\u001b[0m]\u001b[0m\n",
      "\u001b[2m2025-04-07T18:18:22.411363\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel not found in LiteLLM's model_cost.\u001b[0m [\u001b[0m\u001b[1m\u001b[34mcognee.shared.logging_utils\u001b[0m]\u001b[0m\u001b[92m18:18:22 - LiteLLM:INFO\u001b[0m: utils.py:3035 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[1m\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\u001b[0m\u001b[92m18:18:22 - LiteLLM:INFO\u001b[0m: utils.py:3035 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[1m\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\u001b[0m\u001b[92m18:18:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[1mselected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\u001b[0m\u001b[92m18:18:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[1mselected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\u001b[0m\u001b[92m18:18:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[1mselected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\u001b[0m\u001b[92m18:18:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[1mselected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\u001b[0m\u001b[92m18:18:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m18:18:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m18:18:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m18:18:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m18:18:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\n",
      "\u001b[1mReceived notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 8, column: 16, offset: 333} for query: '\\n        UNWIND $nodes AS node\\n        MERGE (n {id: node.node_id})\\n        ON CREATE SET n += node.properties, n.updated_at = timestamp()\\n        ON MATCH SET n += node.properties, n.updated_at = timestamp()\\n        WITH n, node.label AS label\\n        CALL apoc.create.addLabels(n, [label]) YIELD node AS labeledNode\\n        RETURN ID(labeledNode) AS internal_id, labeledNode.id AS nodeId\\n        '\u001b[0m\n",
      "\u001b[1mReceived notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 1, column: 18, offset: 17} for query: 'MATCH (n) RETURN ID(n) AS id, labels(n) AS labels, properties(n) AS properties'\u001b[0m\n",
      "\u001b[1mReceived notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 3, column: 16, offset: 43} for query: '\\n        MATCH (n)-[r]->(m)\\n        RETURN ID(n) AS source, ID(m) AS target, TYPE(r) AS type, properties(r) AS properties\\n        '\u001b[0m\n",
      "\u001b[1mReceived notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 3, column: 33, offset: 60} for query: '\\n        MATCH (n)-[r]->(m)\\n        RETURN ID(n) AS source, ID(m) AS target, TYPE(r) AS type, properties(r) AS properties\\n        '\u001b[0m\u001b[92m18:18:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\n",
      "\u001b[2m2025-04-07T18:18:31.978914\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mPipeline run completed: `af81ab41-8243-522f-a10a-b7b5febcc577`\u001b[0m [\u001b[0m\u001b[1m\u001b[34mrun_tasks(tasks: [Task], data)\u001b[0m]\u001b[0m"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<cognee.modules.pipelines.models.PipelineRun.PipelineRun at 0x334126850>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await cognee.cognify(ontology_file_path=ontology_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mReceived notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 1, column: 18, offset: 17} for query: 'MATCH (n) RETURN ID(n) AS id, labels(n) AS labels, properties(n) AS properties'\u001b[0m\n",
      "\u001b[1mReceived notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 3, column: 16, offset: 43} for query: '\\n        MATCH (n)-[r]->(m)\\n        RETURN ID(n) AS source, ID(m) AS target, TYPE(r) AS type, properties(r) AS properties\\n        '\u001b[0m\n",
      "\u001b[1mReceived notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 3, column: 33, offset: 60} for query: '\\n        MATCH (n)-[r]->(m)\\n        RETURN ID(n) AS source, ID(m) AS target, TYPE(r) AS type, properties(r) AS properties\\n        '\u001b[0m\n",
      "\u001b[2m2025-04-07T18:18:38.008162\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mGraph visualization saved as /Users/handekafkas/graph_visualization.html\u001b[0m [\u001b[0m\u001b[1m\u001b[34mcognee.shared.logging_utils\u001b[0m]\u001b[0m\n",
      "\u001b[2m2025-04-07T18:18:38.008845\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mThe HTML file has been stored on your home directory! Navigate there with cd ~\u001b[0m [\u001b[0m\u001b[1m\u001b[34mcognee.shared.logging_utils\u001b[0m]\u001b[0m"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/handekafkas/graph_visualization.html'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "await visualize_graph()\n",
    "\n",
    "# The file is saved in your current folder\n",
    "home_dir = os.path.expanduser(\"~\")\n",
    "html_file = os.path.join(home_dir, \"graph_visualization.html\")\n",
    "display(html_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Base RAG with query: 'Which exact luxury car model should I choose for quality?' ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:19:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\n",
      "\u001b[2m2025-04-07T18:19:26.489543\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel not found in LiteLLM's model_cost.\u001b[0m [\u001b[0m\u001b[1m\u001b[34mcognee.shared.logging_utils\u001b[0m]\u001b[0m\u001b[92m18:19:26 - LiteLLM:INFO\u001b[0m: utils.py:3035 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[1m\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\u001b[0m\u001b[92m18:19:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[1mselected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\u001b[0m\u001b[92m18:19:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[1mselected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\u001b[0m\n",
      "\u001b[1mReceived notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 1, column: 18, offset: 17} for query: 'MATCH (n) RETURN ID(n) AS id, labels(n) AS labels, properties(n) AS properties'\u001b[0m\n",
      "\u001b[1mReceived notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 3, column: 16, offset: 43} for query: '\\n        MATCH (n)-[r]->(m)\\n        RETURN ID(n) AS source, ID(m) AS target, TYPE(r) AS type, properties(r) AS properties\\n        '\u001b[0m\n",
      "\u001b[1mReceived notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 3, column: 33, offset: 60} for query: '\\n        MATCH (n)-[r]->(m)\\n        RETURN ID(n) AS source, ID(m) AS target, TYPE(r) AS type, properties(r) AS properties\\n        '\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base search results:\n",
      " ['For quality, consider the following luxury car models:\\n\\n1. Audi A8\\n2. BMW 7 Series\\n3. Mercedes S-Class']\n",
      "\n",
      "------ cognee results with query: 'Which exact luxury car model should I choose for quality?' ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:19:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m18:19:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m18:19:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m18:19:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m18:19:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m18:19:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m18:19:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m18:19:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m18:19:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m18:19:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m18:19:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m18:19:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m18:19:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m18:19:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m18:19:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m18:19:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m18:19:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m18:19:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m18:19:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m18:19:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m18:19:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m18:19:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\n",
      "\u001b[2m2025-04-07T18:19:29.672896\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel not found in LiteLLM's model_cost.\u001b[0m [\u001b[0m\u001b[1m\u001b[34mcognee.shared.logging_utils\u001b[0m]\u001b[0m\u001b[92m18:19:29 - LiteLLM:INFO\u001b[0m: utils.py:3035 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[1m\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\u001b[0m\u001b[92m18:19:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[1mselected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\u001b[0m\u001b[92m18:19:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[1mselected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cognee search results:\n",
      " ['For quality luxury cars, you should consider:\\n1. Audi A8\\n2. BMW 7 Series\\n3. Mercedes S-Class\\nAll these models are recognized for their luxury and high-quality engineering.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_1 = (\n",
    "    \"Which exact luxury car model should I choose for safety?\"\n",
    ")\n",
    "\n",
    "print(f\"------ Base RAG with query: '{query_1}' ------\")\n",
    "\n",
    "search_results_base_1 = await cognee.search(\n",
    "    query_type=SearchType.RAG_COMPLETION,\n",
    "    query_text=query_1\n",
    ")\n",
    "\n",
    "print(f\"Base search results:\\n {search_results_base_1}\\n\")\n",
    "\n",
    "\n",
    "print(f\"------ cognee results with query: '{query_1}' ------\")\n",
    "\n",
    "search_results_cognee_1 = await cognee.search(\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    query_text=query_1\n",
    ")\n",
    "\n",
    "print(f\"cognee search results:\\n {search_results_cognee_1}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Base RAG with query: 'I want a German car that focuses on performance and driving pleasure, but also produces an electric model. Which models should I consider?' ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:46:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\n",
      "\u001b[2m2025-04-07T17:46:17.259602\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel not found in LiteLLM's model_cost.\u001b[0m [\u001b[0m\u001b[1m\u001b[34mcognee.shared.logging_utils\u001b[0m]\u001b[0m\u001b[92m17:46:17 - LiteLLM:INFO\u001b[0m: utils.py:3035 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[1m\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\u001b[0m\u001b[92m17:46:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[1mselected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\u001b[0m\u001b[92m17:46:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[1mselected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\u001b[0m\n",
      "\u001b[1mReceived notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 1, column: 18, offset: 17} for query: 'MATCH (n) RETURN ID(n) AS id, labels(n) AS labels, properties(n) AS properties'\u001b[0m\n",
      "\u001b[1mReceived notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 3, column: 16, offset: 43} for query: '\\n        MATCH (n)-[r]->(m)\\n        RETURN ID(n) AS source, ID(m) AS target, TYPE(r) AS type, properties(r) AS properties\\n        '\u001b[0m\n",
      "\u001b[1mReceived notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 3, column: 33, offset: 60} for query: '\\n        MATCH (n)-[r]->(m)\\n        RETURN ID(n) AS source, ID(m) AS target, TYPE(r) AS type, properties(r) AS properties\\n        '\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base search results:\n",
      " ['Consider models like the Porsche Taycan for performance and electric driving pleasure, the BMW i4 for a sporty electric sedan, the Audi e-tron GT for a blend of luxury and performance, and the Mercedes-Benz EQS for a luxurious electric experience. These options focus on high performance while also embracing electric technology.']\n",
      "\n",
      "------ cognee results with query: 'I want a German car that focuses on performance and driving pleasure, but also produces an electric model. Which models should I consider?' ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:46:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m17:46:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m17:46:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m17:46:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m17:46:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m17:46:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m17:46:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m17:46:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m17:46:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m17:46:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m17:46:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m17:46:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m17:46:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m17:46:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m17:46:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m17:46:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m17:46:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m17:46:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m17:46:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m17:46:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m17:46:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m17:46:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\n",
      "\u001b[2m2025-04-07T17:46:20.973460\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel not found in LiteLLM's model_cost.\u001b[0m [\u001b[0m\u001b[1m\u001b[34mcognee.shared.logging_utils\u001b[0m]\u001b[0m\u001b[92m17:46:20 - LiteLLM:INFO\u001b[0m: utils.py:3035 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[1m\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\u001b[0m\u001b[92m17:46:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[1mselected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\u001b[0m\u001b[92m17:46:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[1mselected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cognee search results:\n",
      " ['Consider the following German car models that focus on performance and driving pleasure while also producing electric models: \\n1. Porsche (specifically the Porsche Taycan)\\n2. BMW\\n3. Volkswagen']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_2 = (\n",
    "    \"I want a German car that focuses on performance and driving pleasure, but also produces an electric model. Which models should I consider?\"\n",
    ")\n",
    "\n",
    "print(f\"------ Base RAG with query: '{query_2}' ------\")\n",
    "\n",
    "search_results_base_2 = await cognee.search(\n",
    "    query_type=SearchType.RAG_COMPLETION,\n",
    "    query_text=query_2\n",
    ")\n",
    "\n",
    "print(f\"Base search results:\\n {search_results_base_2}\\n\")\n",
    "\n",
    "\n",
    "print(f\"------ cognee results with query: '{query_2}' ------\")\n",
    "\n",
    "search_results_cognee_2 = await cognee.search(\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    query_text=query_2\n",
    ")\n",
    "\n",
    "print(f\"cognee search results:\\n {search_results_cognee_2}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Base RAG with query: 'Is there a German car manufacturer that both produces a famous sports car and also has an SUV in its lineup? Provide the name and the models.' ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:46:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\n",
      "\u001b[2m2025-04-07T17:46:23.146545\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel not found in LiteLLM's model_cost.\u001b[0m [\u001b[0m\u001b[1m\u001b[34mcognee.shared.logging_utils\u001b[0m]\u001b[0m\u001b[92m17:46:23 - LiteLLM:INFO\u001b[0m: utils.py:3035 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[1m\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\u001b[0m\u001b[92m17:46:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[1mselected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\u001b[0m\u001b[92m17:46:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[1mselected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\u001b[0m\n",
      "\u001b[1mReceived notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 1, column: 18, offset: 17} for query: 'MATCH (n) RETURN ID(n) AS id, labels(n) AS labels, properties(n) AS properties'\u001b[0m\n",
      "\u001b[1mReceived notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 3, column: 16, offset: 43} for query: '\\n        MATCH (n)-[r]->(m)\\n        RETURN ID(n) AS source, ID(m) AS target, TYPE(r) AS type, properties(r) AS properties\\n        '\u001b[0m\n",
      "\u001b[1mReceived notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 3, column: 33, offset: 60} for query: '\\n        MATCH (n)-[r]->(m)\\n        RETURN ID(n) AS source, ID(m) AS target, TYPE(r) AS type, properties(r) AS properties\\n        '\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base search results:\n",
      " ['Yes, Porsche is a German car manufacturer that produces the famous sports car, Porsche 911, and also offers the SUV model, Porsche Macan.']\n",
      "\n",
      "------ cognee results with query: 'Is there a German car manufacturer that both produces a famous sports car and also has an SUV in its lineup? Provide the name and the models.' ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:46:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m17:46:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m17:46:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m17:46:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m17:46:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m17:46:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m17:46:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m17:46:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m17:46:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m17:46:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m17:46:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m17:46:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m17:46:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m17:46:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m17:46:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m17:46:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m17:46:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m17:46:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m17:46:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m17:47:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m17:47:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\u001b[92m17:47:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/text-embedding-3-large\n",
      "\u001b[1mselected model name for cost calculation: openai/text-embedding-3-large\u001b[0m\n",
      "\u001b[2m2025-04-07T17:47:49.193913\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel not found in LiteLLM's model_cost.\u001b[0m [\u001b[0m\u001b[1m\u001b[34mcognee.shared.logging_utils\u001b[0m]\u001b[0m\u001b[92m17:47:49 - LiteLLM:INFO\u001b[0m: utils.py:3035 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[1m\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\u001b[0m\u001b[92m17:47:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[1mselected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\u001b[0m\u001b[92m17:47:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:588 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[1mselected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cognee search results:\n",
      " ['Yes, Porsche is a German car manufacturer that produces a famous sports car and has an SUV in its lineup. \\n- Sports Car: Porsche 911  \\n- SUV: Porsche Cayenne']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_3 = (\n",
    "    \"Is there a German car manufacturer that both produces a famous sports car and also has an SUV in its lineup? Provide the name and the models.\"\n",
    ")\n",
    "\n",
    "print(f\"------ Base RAG with query: '{query_3}' ------\")\n",
    "\n",
    "search_results_base_3 = await cognee.search(\n",
    "    query_type=SearchType.RAG_COMPLETION,\n",
    "    query_text=query_3\n",
    ")\n",
    "\n",
    "print(f\"Base search results:\\n {search_results_base_3}\\n\")\n",
    "\n",
    "\n",
    "print(f\"------ cognee results with query: '{query_3}' ------\")\n",
    "\n",
    "search_results_cognee_3 = await cognee.search(\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    query_text=query_3\n",
    ")\n",
    "\n",
    "print(f\"cognee search results:\\n {search_results_cognee_3}\\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
